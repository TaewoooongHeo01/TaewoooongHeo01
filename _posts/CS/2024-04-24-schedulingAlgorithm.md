---
layout: post
title: OS - Scheduling Algorithm 
category: CS
use_math: true
excerpt: "선점 스케줄링에서는 다수의 프로세스가 CPU 를 놓고 경쟁한다(Race Condition 문제). 이 경우 데이터 일관성 문제가 생길 수 있다. 예를 들어 하나의 자원을 공유하는 두 프로세스가 있다고 하자. 한 프로세스가 자료를 갱신하는 동안, 나머지 프로세스가 자료를 건드리면 이때부터 데이터 일관성이 깨지는 문제가 발생한다. 하지만 비선점 스케줄링과는 반대로 빠르다는 장점이 있다. 

어떤 스케줄링을 선택하느냐는 시스템 마다 다르다. 만약 여러 개의 프로그램들이 동시에 빠르게 돌아가는 유저 친화적인 시스템인 경우, 선점 스케줄링이 유리하다. Windows, macOS, Linux 를 포함한 대부분의 OS 들은 선점 스케줄링을 사용한다. 하지만 자율주행 시스템의 경우 비선점을 선택하는게 더 나을 것이다"
---

OS의 꽃이라 불리는 스케줄링은 가장 핵심적인 부분이다. CPU 에 할당시킬 프로세스를 결정하는 것이 스케줄러가 하는 일이다. 이번엔 스케줄링을 위한 여러가지 알고리즘들에 대해 정리해봤다. 

# Preemtive vs Nonpreemptive Scheduling
CPU 스케줄링의 결정은 다음 네 가지 상황에서 발생할 수 있다. 
- 한 프로세스가 실행 상태에서 **대기 상태**로 전환될 때(예를 들어, I/O 요청이나 wait() 등이 있음)
- 프로세스가 실행 상태에서 **준비 완료 상태**로 전환될 때(예를 들어, 인터럽트가 발생할 때)
- 프로세스가 대기 상태에서 **준비 완료 상태**로 전환될 때(I/O 의 종료)
- 프로세스의 **종료**

프로세스가 종료되거나 대기상태인 경우에만 스케줄링이 일어나는 경우를 `비선점(Nonpreemptive)` 이라고 한다. 만약 종료, 대기를 포함해 준비완료 상태로 전환될 때도 스케줄링이 일어나면 `선점(Preemptive)` 이다. 

**비선점 스케줄링**에서는 프로세스의 **종료 또는 대기 상태**로의 전환이 있기 전까진 프로세스 하나가 계속해서 CPU 를 점유하고 있다. 이러한 비선점 구조는 커널 구조를 단순하게 만든다는 장점이 있지만 주어진 시간 안에 task 를 완료해야 하는 경우 비효율적이고 좋지 않다. 

**선점 스케줄링**에서는 **다수의 프로세스가 CPU 를 놓고 경쟁**한다(Race Condition 문제). 이 경우 데이터 일관성 문제가 생길 수 있다. 예를 들어 하나의 자원을 공유하는 두 프로세스가 있다고 하자. 한 프로세스가 자료를 갱신하는 동안, 나머지 프로세스가 자료를 건드리면 이때부터 데이터 일관성이 깨지는 문제가 발생한다. 하지만 비선점 스케줄링과는 반대로 빠르다는 장점이 있다. 

어떤 스케줄링을 선택하느냐는 시스템 마다 다르다. 만약 여러 개의 프로그램들이 동시에 빠르게 돌아가는 유저 친화적인 시스템인 경우, 선점 스케줄링이 유리하다. Windows, macOS, Linux 를 포함한 대부분의 OS 들은 선점 스케줄링을 사용한다. 하지만 자율주행 시스템의 경우 비선점을 선택하는게 더 나을 것이다("운전"이라는 우선적인 프로세스가 사용중인 CPU 를 비교적 중요하지 않은 다른 프로세스들이 가로채가면 안됨)
# Dispatcher
Dispatcher 는 CPU 코어의 제어를 스케줄러가 선택한 프로세스에 주는 모듈이다. 
- 한 프로세스에서 다른 프로세스로 문맥을 교환
- 사용자모드로 전환
- 적절한 위치로 점프

Dispatcher 는 Context switch 시 호출되므로 최대한 빨리 수행되어야 한다. 이때 Dispatcher 가 하나의 프로세스를 정지하고, 다른 프로세스의 수행을 시작하는데 소요되는 시간을 Dispatch Latency(디스패치 지연) 이라고 한다. 

![](https://i.imgur.com/N3iUOTB.png)

# Scheduling Criteria
서로 다른 스케줄링 알고리즘들을 서로 비교하기 위한 기준들이다. 
- CPU 이용률(utilization) - CPU 를 최대한 바쁘게 해야 한다. CPU 는 놀면 안된다. 
- 처리량(throughput) - 단위 시간당 완료된 프로세스의 개수이다. 
- 총 처리시간(turnaround time) - 총 처리시간은 특정 프로세스가 큐에서 대기한 시간 + CPU 에서 실행한 시간 + I/O 시간을 합한 시간이다.
- 대기 시간(waiting time) - 준비 큐에서 대기하면서 보낸 시간
- 응답 시간(response time) - 하나의 요청 이후 응답이 시작하는데까지 걸리는 시간

이용률과 처리량을 최대화하고, 총 처리시간, 대기시간, 응답시간을 최소화하는 것이 좋다. 

# Scheduling Algorithms
단일 코어 환경이라고 가정하고 설명함. 

스케줄링을 위한 알고리즘들을 본격적으로 살펴본다.
# First-Come, First Served(FCFS)
`선입 선처리(FCFS)` 스케줄링 알고리즘이다. 말 그대로 CPU 를 먼저 요청하는 프로세스가 먼저 CPU 를 할당받는다. 

FIFO 큐로 쉽게 구현이 가능한데, 프로세스가 준비 큐에 들어오면 해당 프로세스의 PCB 를 준비 큐의 맨 마지막에 연결한다. CPU 가 일을 시작하면 준비 큐의 앞에서부터 시작된다.

단점은 각 프로세스마다 걸리는 시간을 고려하지 않고 순차적으로 처리하기 때문에 `평균대기시간` 이 많이 길어질 수 있다. 

만약 이런식으로 배치되어 있으면 많이 곤란해진다.
![](https://i.imgur.com/9nguDVF.png)
평균 시간이 17 밀리초가 나와버린다. 이러면 P2, P3 는 P1 이 끝날때까지 계속 기다려야 한다 => 결국 CPU 와 전반적인 장치 이용률이 낮아지게 된다(호위효과, Convoy Effect)

하지만 이렇게 배치하면 훨씬 효율적이다.
![](https://i.imgur.com/4dw97Io.png)
평균 시간이 3 밀리초로 많이 단축되었다. 

FCFS 스케줄링 알고리즘은 비선점형이다. 하나의 프로세스가 끝날때까지 CPU 를 놓아주지 않는다. 

+FCFS 에 대한 궁금증<br>
긴 CPU 버스트를 가진 프로세스 P1 과 P2 가 있다고 해보자. P1 이 먼저 CPU 를 점유한 상태에서 I/O 요청을 만나면, P1 은 I/O 버스트상태가 된다. 그리고 CPU 는 P2 를 처리한다. 이때 P1 이 I/O 요청을 끝내고 준비상태로 돌아오면? -> 어쨌든 FCFS 는 비선점 방식이기 때문에 CPU 는 P2 가 끝나야 P1 을 마저 처리할 것이다.

+I/O 중심의 프로세스라면 호위효과가 발생할 확률이 적지 않을까? -> 맞음
긴 처리시간을 갖고 있는 프로세스라도 I/O 요청이 들어오면 I/O 처리를 위해 I/O 장치로 이동한다. 이때 CPU 는 다음 프로세스를 처리한다. 이 경우엔 모든 장치가 활용됨
# Shortest-Job-First Scheduling
이번엔 `최단 작업 우선(shortest-job-first, SJF)` 스케줄링 알고리즘이다. 다음 CPU Burst 가 가장 짧은 프로세스부터 실행시킨다.

![](https://i.imgur.com/eOVdGTZ.png)

SJF 스케줄링 알고리즘은 `Preemptive` 방식과 `Non-preemptive` 방식으로 나뉜다. 이건 그냥 기존의 선점, 비선점 방식에 SJF 방식만 추가한 것이다. 다음에 올 프로세스를 SJF 방식으로 정한다.

`Non-preemptive SJF Scheduling` 의 예시
![](https://i.imgur.com/Nw2U2U1.png)
각각 프로세스마다 Arrival Time 과 Burst Time 이 있다. P1 의 도착시간이 0.0 ms 으로 가장 먼저 도착했으므로 7 의 Burst Time 만큼 CPU 를 점유한다. 이때 비선점 방식이므로 P1 이 끝날때까지 아무도 못 건드린다. P1 이 실행되는 동안 P2, P3, P4 가 모두 준비큐에 도착했다. 여기서 Burst Time 이 가장 짧은 프로세스는 P3 이므로 P3 가 다음으로 실행된다. P2, P4 의 Burst Time 은 똑같다. 이 경우엔 FCFS 방식으로 결정된다. 따라서 P2 이후 마지막으로 P4 가 실행된다. 

`Preemptive SJF Scheduling` 의 예시
![](https://i.imgur.com/tw1gwwk.png)
가장 처음으로 들어온 P1 부터 시작한다. 그러다 2.0 ms 에 P2 가 준비큐에 들어온다. P1 의 Burst Time 은 2만큼 소모했으므로 남은 Burst Time 은 5이다. 이제 들어온 P2 는 4 의 Burst  Time 을 가지고 있으므로 P2 가 실행된다. 나머지도 동일한 규칙을 따른다. 

SJF 스케줄링 알고리즘은 평균 대기시간 면에서 최적의 알고리즘이지만, CPU Burst 의 길이를 미리 알 방법이 없다는 것이 문제다. 이때 한 가지 방법은 근삿값으로 예측하는 것이다.

이전 값을 이용해 다음 값을 예측하는데, 이때 이전의 CPU Burst 들의 길이를 지수 평균(expotential average)한 것으로 예측한다.

$t_{n}$ = n 번째 CPU Burst 길이

$\tau_{n+1}$ = 다음 CPU Burst 예측값

<br>
공식은 다음과 같다.

$\tau_{n+1} = \alpha t_{n} + (1 - \alpha) \tau_{n}$   

여기서 $\alpha$ 는 이전 값들을 통해 예측할 때 $t_{n}$ 과 $\tau_{n}$ 중 어떤 것에 더욱 많은 비중을 둘 지 결정하는 매개변수이다. 그러니까 1 에 가까울 수록 $t_{n}$ (바로 이전의 CPU Burst 실제 길이)에 좀 더 비중을 두고, 0 에 가까울 수록 $\tau_{n}$ (바로 이전의 예측값) 이 좀 더 비중을 갖는다. 이 매개변수를 잘 조정해야 정확도를 높일 수 있다. 
$(0 \le \alpha \le 1)$

![](https://i.imgur.com/uDrLTEr.png)

# Round Robin(RR)
`Round Robin(RR)` 스케줄링 알고리즘은 FCFS 와 유사하지만, "시간" 이라는 개념이 추가되었다. 각 프로세스마다 `시간할당량(time quantum)` 을 추가하고, 해당 시간만큼까지만 CPU 를 사용할 수 있도록 제한한다. 준비 큐는 원형 큐로 FCFS 로 동작할 수 있도록 한다. 

동작 방식을 구체적으로 살펴보면, 스케줄러는 가장 먼저 실행 될 프로세스에 "시간 할당량이 끝나면 인터럽트를 걸도록" 타이머를 설정한 후, dispatch 한다. 이때 두 가지 경우가 있다. 
- CPU Burst > 시간할당량
- CPU Burst < 시간할당량

만약 CPU Burst 가 시간할당량 보다 짧다면, 그냥 실행하고 알아서 종료된다. 주목할 것은 CPU Burst 가 시간할당량 보다 긴 경우다. 이 경우 타이머에 설정한 시간에 도달하면 프로세스 처리가 끝나지 않아도 프로세스 내부의 타이머가 인터럽트를 발생시킨다. 그리고 해당 프로세스는 다시 준비큐로 들어간 뒤 다음 프로세스가 CPU 를 점유한다. 

![](https://i.imgur.com/gyNikEf.png)
유일하게 실행 가능한 프로세스가 아니라면, 두 번 연속 실행될 순 없다.

RR 은 일반적으로 평균처리 시간이 길지만, 응답성이 좋다. 여기서 응답성이 좋다 라는 것은 사용자의 작업에 빠르게 반응할 수 있는 것을 의미한다. 

![](https://i.imgur.com/HAKjqv4.png)
RR 알고리즘의 성능은 시간할당량에 매우 큰 영향을 받는다. 만약 시간 할당량이 매우 크면 FCFS 알고리즘과 다를게 없어진다. 반면, 시간할당량이 매우 작으면 Context Switch 가 빈번하게 일어나 프로세스의 실행이 느려질 수 있다. 

일반적으로, 80% 이상의 프로세스들이 단일 시간할당량 안에 끝나면 총처리 시간(turnaround time) 이 개선된다. 알아야 할 것은 무작정 늘린다고 향상되는 건 아니라는 것이다.

# Priority Scheduling
`우선순위 스케줄링(Priority Scheduling)` 은 가장 높은 우선순위를 가진 프로세스 CPU 를 점유하는 방식이다. 위에서 설명한 `SJF(Shortest Job First)` 방식도 우선순위 스케줄링의 한 종류다.

우선순위는 내부적 또는 외부적으로 결정된다. 내부적 기준은 측정 가능한 양을 사용하는데, 예를 들어 시간 제한, 메모리 요구, 열린 파일의 개수 등이 있다. 외부적 기준은 운영체제 외부의 기준들이다. 프로세스의 중요성, 컴퓨터 사용을 위해 지불되는 비용 등이 있다. 

우선순위 스케줄링의 문제는 `기아(starvation)` 이다. 낮은 우선순위에 있는 프로세스들은 계속해서 CPU 를 사용하지 못하는 문제다. 높은 우선순위의 프로세스들이 꾸준히 들어오는 경우에 발생한다. 이러면 결국 두 가지 상황이 발생한다. 
- 오랜 시간 뒤에 결국 실행됨
- 낮은 프로세스들을 잃어버림

한가지 솔루션은 `노화(aging)` 이다. 노화는 오랫동안 대기하는 프로세스들의 우선순위를 점진적으로 증가시킨다. 이러면 우선순위가 낮더라도 실행이 안되는 일은 없을 것이다. 

# Multilevel Queue Scheduling
우선순위 스케줄링에서 모든 프로세스들을 단일 큐에 넣는다면, 다음 우선순위를 찾기까지 $O(n)$ 이 걸릴 것이다. 

이때 우선순위를 기준으로 여러 개의 큐를 만들면 더 쉬울 수도 있다. 이것을 `다단계 큐 스케줄링(Multilevel Queue Scheduling)` 이라고 한다.
![](https://i.imgur.com/Vd5nnR3.png)
우선순위가 높은 프로세스를 갖고 있는 큐부터 `RR` 순서로 실행된다. 프로세스는 실행시간 동안 동일한 큐에 남아있다.

프로세스 유형에 따라 큐를 분리할 수도 있다. 
![](https://i.imgur.com/t5SQ5G4.png)
`interactive processes` 들은 사용자와의 상호작용을 하는 프로세스들(ex) 텍스트 편집기, 브라우저 등 응용프로그램) 이다. 이들은 `batch processes` 들 보다 높은 우선순위를 갖는다. 이렇게 각각 포그라운드와 백그라운드 프로세스들이 우선순위에 따라 별도의 큐에서 관리된다. 

또한 각각의 큐는 각자의 스케줄링 방식을 가질 수 있다. 예를 들어 포그라운드 큐는 `RR`, 백그라운드 큐는 `FCFS` 를 가질 수 있다. 

큐들 사이의 스케줄링 방식도 결정해야 한다. 두 가지 선택지가 있다. 
1. 고정 우선순위 스케줄링
각 큐는 절대적인 우선순위를 가진다. 높은 우선순위의 큐가 비어있어야 낮은 우선순위 큐가 실행될 수 있다. 
2. 타임 슬라이스 스케줄링
다른 방법은 큐들 사이에 시간을 나눠 사용하는 것이다. 큐는 각자의 가중치를 부여받고, 해당 가중치를 기준으로 CPU 에 할당된다. 예를 들어 포그라운드 큐는 CPU 시간의 80% 를 부여받고, 백그라운드 큐는 나머지 20% 를 할당받는 방식이다.

# Multilevel Feedback Queue
위에서 이야기 한 `다단계 큐 스케줄링 알고리즘` 에서는 프로세스가 한 큐에서 다른 큐로 이동하는 것을 허용하지 않는다. 프롯세스의 특성이 바뀌지 않기 때문인데, 이것은 적은 오버헤드의 장점이 있지만, 융통성이 적다.

`다단계 피드백 큐(Multilevel Feedback Queue)` 스케줄링 알고리즘에서는 프로세스가 큐들 사이를 이동하는 것을 허용한다. 

처음 출발은 적은 CPU Burst 를 가진 프로세스들을 우선적으로 배치한다. 가장 앞의 큐에 있는 프로세스부터 실행된다. 실행되면서 CPU 를 너무 오래 사용하면 순서가 뒤로 밀려날 수 있다. 반대로 너무 오래 대기하면(starvation) 우선순위가 높아진다(aging). 이 과정에서 프로세스들을 큐 사이를 이동한다. 

![](https://i.imgur.com/OsgUnV9.png)
Q0, Q1, Q2 가 있다. Q0, Q1 는 각각 8 과 16 의 시간할당량을 가지고 있고 Q2 는 FCFS 방식이다. 

진행되는 방식을 설명하자면, 가장 먼저 Q0 이 비어있어야 Q1 에 있는 프로세스들을 실행할 수 있다. 또한 Q1 이 비어있어야 Q2 에 있는 프로세스들을 실행할 수 있다. 

새로운 프로세스가 들어오면, 8ms 의 시간할당량을 부여받고 Q0 에 들어온다. 만약 해당 프로세스가 8ms 안에 끝나지 않으면 Q1 의 tail 에 추가된다. 16ms 에도 끝나지 않으면 Q2 에 추가될 것이다.

Q0 이 비어있는 경우, Q1 의 head 부터 16ms 의 시간할당량이 부여된다. 그리고 CPU 를 사용한다. 이런식으로 반복된다.

다단계 피드백 큐 스케줄링 알고리즘은 다음의 매개변수에 의해 정해진다. 
- 큐의 개수
- 각 큐를 위한 스케줄링 알고리즘
- 한 프로세스를 높은 우선순위 큐로 올려주는 시기를 결정하는 방법
- 한 프로세스를 낮은 우선순위 큐로 강등시키는 시기를 결정하는 방법
- 프로세스에 서비스가 필요할 때 프로세스가 들어갈 큐를 결정하는 방법(=CPU 사용을 위해 큐로 들어갈 때 어떤 큐로 들어갈 지 결정하는 방법)

### References
- Operating System Concepts - Book by Abraham Silberschatz, Greg Gagne, and Peter Baer Galvin
